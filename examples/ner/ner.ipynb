{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install allennlp==2.5.0\n",
    "# !pip install allennlp-models==2.5.0\n",
    "# !git clone https://github.com/mhagiwara/realworldnlp.git\n",
    "# %cd realworldnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin_paulhykim_altostrat_com/realworldnlp\n"
     ]
    }
   ],
   "source": [
    "%cd /home/admin_paulhykim_altostrat_com/realworldnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import chain\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.data_loaders import MultiProcessDataLoader\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import TextField, SequenceLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.samplers import BucketBatchSampler\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.token_class import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy, SpanBasedF1Measure\n",
    "from allennlp.training import GradientDescentTrainer\n",
    "from overrides import overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDatasetReader(DatasetReader):\n",
    "    def __init__(self, file_path: str, token_indexers: Dict[str, TokenIndexer]=None):\n",
    "        super().__init__()\n",
    "        self.token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
    "\n",
    "        self.instances = []\n",
    "        file_path = cached_path(file_path)\n",
    "        sentence = []\n",
    "        with open(file_path, mode='r', encoding='utf-8', errors='ignore') as csv_file:\n",
    "            next(csv_file)\n",
    "            reader = csv.reader(csv_file)\n",
    "\n",
    "            for row in reader:\n",
    "                if row[0] and sentence:\n",
    "                    tokens, labels = self._convert_sentence(sentence)\n",
    "                    self.instances.append(self.text_to_instance(tokens, labels))\n",
    "\n",
    "                    sentence = [row]\n",
    "                else:\n",
    "                    sentence.append(row)\n",
    "\n",
    "            if sentence:\n",
    "                tokens, labels = self._convert_sentence(sentence)\n",
    "                self.instances.append(self.text_to_instance(tokens, labels))\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], labels: List[str]=None):\n",
    "        fields = {}\n",
    "\n",
    "        text_field = TextField(tokens, self.token_indexers)\n",
    "        fields['tokens'] = text_field\n",
    "        if labels:\n",
    "            fields['labels'] = SequenceLabelField(labels, text_field)\n",
    "\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _convert_sentence(self, rows: List[Tuple[str]]) -> Tuple[List[Token], List[str]]:\n",
    "        \"\"\"Given a list of rows, returns tokens and labels.\"\"\"\n",
    "        _, tokens, _, labels = zip(*rows)\n",
    "        tokens = [Token(t) for t in tokens]\n",
    "\n",
    "        # NOTE: the original dataset seems to confuse gpe with geo, and the distinction\n",
    "        # seems arbitrary. Here we replace both with 'gpe'\n",
    "        labels = [label.replace('geo', 'gpe') for label in labels]\n",
    "        return tokens, labels\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, split: str):\n",
    "        for i, inst in enumerate(self.instances):\n",
    "            if split == 'train' and i % 10 != 0:\n",
    "                yield inst\n",
    "            elif split == 'dev' and i % 10 == 0:\n",
    "                yield inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmTagger(Model):\n",
    "    def __init__(self,\n",
    "                 embedder: TextFieldEmbedder,\n",
    "                 encoder: Seq2SeqEncoder,\n",
    "                 vocab: Vocabulary, \n",
    "                 cuda_device=-1) -> None:\n",
    "        super().__init__(vocab)\n",
    "        self.embedder = embedder\n",
    "        self.encoder = encoder\n",
    "        self.hidden2labels = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
    "                                             out_features=vocab.get_vocab_size('labels'))\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.f1 = SpanBasedF1Measure(vocab, tag_namespace='labels')\n",
    "        \n",
    "        if cuda_device > -1:\n",
    "            self.hidden2labels = self.hidden2labels.to(cuda_device)\n",
    "            self.embedder = self.embedder.to(cuda_device)\n",
    "            self.encoder = self.encoder.to(cuda_device)\n",
    "\n",
    "    def forward(self,\n",
    "                tokens: Dict[str, torch.Tensor],\n",
    "                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.embedder(tokens)\n",
    "        encoder_out = self.encoder(embeddings, mask)\n",
    "        logits = self.hidden2labels(encoder_out)\n",
    "        output = {'logits': logits}\n",
    "        if labels is not None:\n",
    "            self.accuracy(logits, labels, mask)\n",
    "            self.f1(logits, labels, mask)\n",
    "            output['loss'] = sequence_cross_entropy_with_logits(logits, labels, mask)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        f1_metrics = self.f1.get_metric(reset)\n",
    "        return {'accuracy': self.accuracy.get_metric(reset),\n",
    "                'prec': f1_metrics['precision-overall'],\n",
    "                'rec': f1_metrics['recall-overall'],\n",
    "                'f1': f1_metrics['f1-measure-overall']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = NERDatasetReader('https://s3.amazonaws.com/realworldnlpbook/data/entity-annotated-corpus/ner_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b86567c8b3c4b038ee845e75112a1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d3e817d3894dde9460757721c5dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = BucketBatchSampler(batch_size=16, sorting_keys=[\"tokens\"])\n",
    "train_data_loader = MultiProcessDataLoader(reader, 'train', batch_sampler=sampler)\n",
    "dev_data_loader = MultiProcessDataLoader(reader, 'dev', batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fac1ecf3ce41beb7e4e7b6fdb2cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(chain(train_data_loader.iter_instances(),\n",
    "                                        dev_data_loader.iter_instances()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader.index_with(vocab)\n",
    "dev_data_loader.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokens: List[str], model: LstmTagger) -> List[str]:\n",
    "    token_indexers = {'tokens': SingleIdTokenIndexer()}\n",
    "    tokens = [Token(t) for t in tokens]\n",
    "    inst = Instance({'tokens': TextField(tokens, token_indexers)})\n",
    "    logits = model.forward_on_instance(inst)['logits']\n",
    "    label_ids = np.argmax(logits, axis=1)\n",
    "    labels = [model.vocab.get_token_from_index(label_id, 'labels')\n",
    "              for label_id in label_ids]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_SIZE)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = PytorchSeq2SeqWrapper(\n",
    "    torch.nn.LSTM(EMBEDDING_SIZE, HIDDEN_SIZE, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmTagger(word_embeddings, lstm, vocab, cuda_device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca0048382554916a377466bf1c50a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964918a56c847c7a1bd83e0a04bce7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c305e4a40476da10709c74ce0092e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8fe6df8b3046aa9bf9cad454df0443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e077edf4d43d585db2fb033c11401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8190ce5f62d48a4af7e0afaa67295bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f37c18cbca14d7798806fcb772293e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5014d507b4804bbe86bafd23b2c1281b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b81c409a01f49edb1b2ba991ba34165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed8b905b8144107a7ea2edc36930a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc9927b9e094e9aada304dd00325461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d1221928f74f259011e35ac0736e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f1ad4d9f1f49149d31c7a9c1bb2570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9776bfbce14c96bce49bd035e5a3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826723008c1c4e6a9809d723aa05c996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91176dbeaec94ada9fec88b8c5422bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc5df477a8f4b428c8d9008f2222cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b3267cc8e445b0b361334e24b98efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728f52318c3f4f7c9d68b691eb2b17b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae5d740d0cd48a8930d4ecfc1ad097c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e655c0f3cd3d4794811db1307878e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4cc07b18dd49229988343b507e5b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dd03f4b1a64f8a8c3ea46fec3601ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1907047de2324497b6a118f3c582e018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 1,\n",
       " 'peak_worker_0_memory_MB': 5912.12890625,\n",
       " 'peak_gpu_0_memory_MB': 112.1611328125,\n",
       " 'training_duration': '0:06:01.571743',\n",
       " 'epoch': 11,\n",
       " 'training_accuracy': 0.996590541879228,\n",
       " 'training_prec': 0.9733036817395602,\n",
       " 'training_rec': 0.9774773433389913,\n",
       " 'training_f1': 0.9753860478015329,\n",
       " 'training_loss': 0.009491482226074434,\n",
       " 'training_worker_0_memory_MB': 5912.12890625,\n",
       " 'training_gpu_0_memory_MB': 112.1611328125,\n",
       " 'validation_accuracy': 0.9638880931920175,\n",
       " 'validation_prec': 0.7816926036020283,\n",
       " 'validation_rec': 0.802027269465375,\n",
       " 'validation_f1': 0.7917293898874911,\n",
       " 'validation_loss': 0.1795651229872601,\n",
       " 'best_validation_accuracy': 0.9699322066265635,\n",
       " 'best_validation_prec': 0.8283081327726581,\n",
       " 'best_validation_rec': 0.8304628632938643,\n",
       " 'best_validation_f1': 0.8293840985441829,\n",
       " 'best_validation_loss': 0.09080706231839333}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = GradientDescentTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_data_loader,\n",
    "    validation_data_loader=dev_data_loader,\n",
    "    patience=10,\n",
    "    num_epochs=20,\n",
    "    cuda_device=0)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple/B-org is/O looking/O to/O buy/O U.K./O startup/O for/O $1/O billion/O ./O\n"
     ]
    }
   ],
   "source": [
    "tokens = ['Apple', 'is', 'looking', 'to', 'buy', 'U.K.', 'startup', 'for', '$1', 'billion', '.']\n",
    "labels = predict(tokens, model)\n",
    "print(' '.join('{}/{}'.format(token, label) for token, label in zip(tokens, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
